{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoQzkLrNQqAnoL+WoyjJ0H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raseeec/APD_24-0/blob/main/Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "N6S935l5TXiC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('BancoDataset.csv')#Importamos data\n",
        "df = pd.DataFrame(data)\n",
        "#Ahora borramos las columnas que no se usarán y además sacamos la cantidad de datos que no conocemos\n",
        "df = df.iloc[:, 1:-2]\n",
        "df.replace('Unknown', pd.NA, inplace=True)#Reemplazamos los Unknown a null, para luego imputarlos mediante la media\n",
        "central_values = df.median()\n",
        "df = df.fillna(df.mode().iloc[0])\n",
        "print(df.head())\n",
        "df#Data imputada"
      ],
      "metadata": {
        "id": "0bhdhHD5UuB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Education_Level'] = pd.Categorical(df['Education_Level'], categories=[\"Uneducated\", \"High School\", \"College\", \"Graduate\", \"Post-Graduate\", \"Doctorate\"], ordered=True)\n",
        "df = df.sort_values(by='Education_Level')\n",
        "df#Este será nuestro DataFrame"
      ],
      "metadata": {
        "id": "2JoemknsU6R0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['Attrition_Flag'])  # Características\n",
        "y = df['Attrition_Flag']  # Etiquetas\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)\n",
        "print(X_train.shape)#Para el training\n",
        "print(X_test.shape)#Para el test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vmqb4pD_U2Xp",
        "outputId": "4b4d7836-5103-41d8-df88-ef4b0e86d5f1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7088, 19)\n",
            "(3039, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_encoded = pd.get_dummies(X_train)#Convertimos las variables categóricas en variables dummy (one-hot encoded) antes de entrenar el modelo\n",
        "X_test_encoded = pd.get_dummies(X_test)\n",
        "label_encoder = LabelEncoder().fit(y_train)#Convertir etiquetas de clase a valores numéricos\n",
        "y_train_encoded = label_encoder.transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "#Normalizamos los datos\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
        "X_test_scaled = scaler.transform(X_test_encoded)"
      ],
      "metadata": {
        "id": "0MUfGCt3Vj_y"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = Sequential()\n",
        "modelo.add(Dense(units=64, activation='relu', input_dim=X_train_scaled.shape[1]))#Capa de entrada\n",
        "modelo.add(Dense(units=32, activation='relu'))#Capa oculta\n",
        "modelo.add(Dense(units=1, activation='sigmoid'))#Capa de salida\n",
        "\n",
        "#Compilar el modelo\n",
        "modelo.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "#Usamos el algoritmo de optimización adam, binary crossentropy se usa en problemas de clasificación binaria, la métrica elegida es la precisión-accuracy\n",
        "\n",
        "#Entrenar el modelo\n",
        "history = modelo.fit(X_train_scaled, y_train_encoded, epochs=50, batch_size=7088, validation_data=(X_test_scaled, y_test_encoded))\n",
        "#epochs, es el numero de iteraciones, ponemos toda la data de training, entonces hacemos un full batch training\n",
        "\n",
        "#Evaluar el modelo en el conjunto de prueba\n",
        "loss, accuracy = modelo.evaluate(X_test_scaled, y_test_encoded)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca3GpHDdV6N_",
        "outputId": "9b5b7c34-09d0-4152-b5e3-99ac4532b648"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 1s 906ms/step - loss: 0.7816 - accuracy: 0.3938 - val_loss: 0.7474 - val_accuracy: 0.4459\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.7468 - accuracy: 0.4403 - val_loss: 0.7145 - val_accuracy: 0.4962\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.7142 - accuracy: 0.4973 - val_loss: 0.6837 - val_accuracy: 0.5610\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6839 - accuracy: 0.5566 - val_loss: 0.6552 - val_accuracy: 0.6203\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6558 - accuracy: 0.6117 - val_loss: 0.6290 - val_accuracy: 0.6706\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6300 - accuracy: 0.6614 - val_loss: 0.6050 - val_accuracy: 0.7127\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6063 - accuracy: 0.7056 - val_loss: 0.5831 - val_accuracy: 0.7562\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5848 - accuracy: 0.7462 - val_loss: 0.5632 - val_accuracy: 0.7746\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.5652 - accuracy: 0.7714 - val_loss: 0.5453 - val_accuracy: 0.7963\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.5475 - accuracy: 0.7949 - val_loss: 0.5292 - val_accuracy: 0.8134\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.5317 - accuracy: 0.8090 - val_loss: 0.5149 - val_accuracy: 0.8220\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.5175 - accuracy: 0.8197 - val_loss: 0.5022 - val_accuracy: 0.8312\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.5048 - accuracy: 0.8275 - val_loss: 0.4908 - val_accuracy: 0.8365\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.4934 - accuracy: 0.8320 - val_loss: 0.4808 - val_accuracy: 0.8384\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.4833 - accuracy: 0.8348 - val_loss: 0.4718 - val_accuracy: 0.8391\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.4743 - accuracy: 0.8358 - val_loss: 0.4638 - val_accuracy: 0.8397\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.4662 - accuracy: 0.8372 - val_loss: 0.4566 - val_accuracy: 0.8411\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4589 - accuracy: 0.8376 - val_loss: 0.4502 - val_accuracy: 0.8417\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4522 - accuracy: 0.8378 - val_loss: 0.4443 - val_accuracy: 0.8417\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.4460 - accuracy: 0.8379 - val_loss: 0.4388 - val_accuracy: 0.8417\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4404 - accuracy: 0.8382 - val_loss: 0.4337 - val_accuracy: 0.8417\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.4350 - accuracy: 0.8382 - val_loss: 0.4288 - val_accuracy: 0.8417\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.4299 - accuracy: 0.8382 - val_loss: 0.4242 - val_accuracy: 0.8417\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4250 - accuracy: 0.8382 - val_loss: 0.4197 - val_accuracy: 0.8417\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4202 - accuracy: 0.8382 - val_loss: 0.4153 - val_accuracy: 0.8417\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.4155 - accuracy: 0.8382 - val_loss: 0.4110 - val_accuracy: 0.8417\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4109 - accuracy: 0.8382 - val_loss: 0.4067 - val_accuracy: 0.8417\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.4063 - accuracy: 0.8382 - val_loss: 0.4025 - val_accuracy: 0.8417\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.4018 - accuracy: 0.8382 - val_loss: 0.3983 - val_accuracy: 0.8417\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.3973 - accuracy: 0.8382 - val_loss: 0.3942 - val_accuracy: 0.8417\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.3928 - accuracy: 0.8382 - val_loss: 0.3901 - val_accuracy: 0.8417\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.3884 - accuracy: 0.8382 - val_loss: 0.3861 - val_accuracy: 0.8417\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3841 - accuracy: 0.8382 - val_loss: 0.3822 - val_accuracy: 0.8417\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.3798 - accuracy: 0.8382 - val_loss: 0.3783 - val_accuracy: 0.8421\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.3756 - accuracy: 0.8385 - val_loss: 0.3746 - val_accuracy: 0.8427\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.3716 - accuracy: 0.8386 - val_loss: 0.3709 - val_accuracy: 0.8434\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.3676 - accuracy: 0.8394 - val_loss: 0.3674 - val_accuracy: 0.8444\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.3638 - accuracy: 0.8406 - val_loss: 0.3639 - val_accuracy: 0.8473\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.3601 - accuracy: 0.8417 - val_loss: 0.3606 - val_accuracy: 0.8493\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.3565 - accuracy: 0.8435 - val_loss: 0.3575 - val_accuracy: 0.8500\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.3531 - accuracy: 0.8447 - val_loss: 0.3544 - val_accuracy: 0.8509\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.3499 - accuracy: 0.8478 - val_loss: 0.3515 - val_accuracy: 0.8542\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.3467 - accuracy: 0.8502 - val_loss: 0.3488 - val_accuracy: 0.8559\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.3437 - accuracy: 0.8534 - val_loss: 0.3461 - val_accuracy: 0.8595\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.3408 - accuracy: 0.8571 - val_loss: 0.3435 - val_accuracy: 0.8621\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.3380 - accuracy: 0.8612 - val_loss: 0.3411 - val_accuracy: 0.8644\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.3353 - accuracy: 0.8637 - val_loss: 0.3387 - val_accuracy: 0.8671\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.3327 - accuracy: 0.8663 - val_loss: 0.3364 - val_accuracy: 0.8684\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3301 - accuracy: 0.8674 - val_loss: 0.3341 - val_accuracy: 0.8687\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.3277 - accuracy: 0.8702 - val_loss: 0.3320 - val_accuracy: 0.8704\n",
            "95/95 [==============================] - 0s 3ms/step - loss: 0.3320 - accuracy: 0.8704\n",
            "Loss: 0.3319644033908844\n",
            "Accuracy: 0.8703520894050598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRAFICO"
      ],
      "metadata": {
        "id": "DWZHvnpsd9DX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plot_model(modelo, to_file='a.png', show_shapes=True, show_layer_names=True)\n",
        "#img = plt.imread('modelo.png')\n",
        "#plt.figure(figsize=(10, 7))\n",
        "#plt.imshow(img)\n",
        "#plt.axis('off')\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "MLRBT0Klcczo"
      },
      "execution_count": 61,
      "outputs": []
    }
  ]
}